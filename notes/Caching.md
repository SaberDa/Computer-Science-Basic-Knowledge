# Cache

Load balancing 的目的在于在数量不断增加的服务器上进行横向扩展，Caching 的目的在于使更好的利用现有资源，并使之前无法达到的产品需求变的可行。缓存利用了引用原则的局部性：最近请求的数据可能会被再次请求。这个几乎被应用于计算机的每个层：硬件，操作系统，Web浏览器，Web应用程序。

高速缓存就像短期内存：它具有有限的空间量，但是通常比原始数据源快，并且其包含最近访问的项目。缓存可以存在于体系结构的所有级别，但是通常位于最接近前端的级别。缓存的实现是为了在不增加下游级别负担的条件下，能够快速地返回数据。

---

### 1. Application server cache

将 cache 直接放置在请求层结点上，可以实现相应数据的本地储存。每次对服务器提出请求时，结点将快速返回本地缓存的数据（如果其存在的话）。如果被请求的数据不在 cache 中，那么请求结点将从磁盘中查询数据。一个请求层结点上的 cache 可以存在于内存之中（速度非常快），也存在于本地磁盘上（比网络储存要快）。

将其扩展到许多结点时会发生什么？如果请求层扩展到多个结点，那么每个结点仍然有可能托管其自身的 cache。但是如果负债均衡器在结点之间随机分配请求，那么相同的请求可能会到达不同的结点，从而导致缓存丢失率的增加。我们可以使用全局缓存或者分布式缓存解决该问题。


---

### 2. Distributed cache

---

### 3. Global cache

---

### 4. Content distribute network (CDN)

---

## Cache Invalidation

---

## Cache eviction policies